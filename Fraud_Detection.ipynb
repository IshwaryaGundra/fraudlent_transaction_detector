{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "            Time         V1         V2        V3        V4        V5  \\\n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...       V21       V22  \\\n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "credit_card_data=pd.read_csv(r\"creditcard.csv\")\n",
    "'''print(credit_card_data.info())'''\n",
    "print(credit_card_data.head())\n",
    "print(credit_card_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CHECKING THE MISSING VALUES IN THE EACH COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(credit_card_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DISTRIBUTION OF LEGIT(AUTHORIZED) TRANSACTIONS AND FRADULENT TRANSACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "''' 0 represents the normal transactions and 1 represents the fraudlent transactions'''\n",
    "print(credit_card_data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SEPARATING THE DATA FOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of legit is : (284315, 31)\n",
      "Shape of fraudlent is : (492, 31)\n"
     ]
    }
   ],
   "source": [
    "legit=credit_card_data[credit_card_data.Class==0]\n",
    "fraudlent=credit_card_data[credit_card_data.Class==1]\n",
    "'''print(legit)'''\n",
    "'''print(fraudlent)'''\n",
    "print(\"Shape of legit is :\",legit.shape)\n",
    "print(\"Shape of fraudlent is :\",fraudlent.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#STATISTICAL MEASURES OF THE DATA LEGIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legit Statistical Measures:\n",
      "count    284315.000000\n",
      "mean         88.291022\n",
      "std         250.105092\n",
      "min           0.000000\n",
      "25%           5.650000\n",
      "50%          22.000000\n",
      "75%          77.050000\n",
      "max       25691.160000\n",
      "Name: Amount, dtype: float64\n",
      "Fraudlent Statistical Measures:\n",
      "count     492.000000\n",
      "mean      122.211321\n",
      "std       256.683288\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         9.250000\n",
      "75%       105.890000\n",
      "max      2125.870000\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Legit Statistical Measures:\")\n",
    "print(legit.Amount.describe())\n",
    "print(\"Fraudlent Statistical Measures:\")\n",
    "print(fraudlent.Amount.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARE THE VALUES FOR BOTH TRANSACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Time        V1        V2        V3        V4        V5  \\\n",
      "Class                                                                   \n",
      "0      94838.202258  0.008258 -0.006271  0.012171 -0.007860  0.005453   \n",
      "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
      "\n",
      "             V6        V7        V8        V9  ...       V20       V21  \\\n",
      "Class                                          ...                       \n",
      "0      0.002419  0.009637 -0.000987  0.004467  ... -0.000644 -0.001235   \n",
      "1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n",
      "\n",
      "            V22       V23       V24       V25       V26       V27       V28  \\\n",
      "Class                                                                         \n",
      "0     -0.000024  0.000070  0.000182 -0.000072 -0.000089 -0.000295 -0.000131   \n",
      "1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n",
      "\n",
      "           Amount  \n",
      "Class              \n",
      "0       88.291022  \n",
      "1      122.211321  \n",
      "\n",
      "[2 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(credit_card_data.groupby('Class').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNDER SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "101598   67889.0 -0.368669  1.095595  1.270223  0.071694 -0.019542 -0.946124   \n",
      "251429  155344.0 -0.820185  0.765186  0.568137 -0.521165  0.690793 -0.124059   \n",
      "73800    55285.0 -0.614611 -0.713327  1.756478 -2.087375 -1.096341  0.286983   \n",
      "3896      3469.0 -0.054135  0.851364  0.372174  0.627681 -0.302748 -0.380554   \n",
      "52306    45379.0 -0.358544  0.563827  1.203042 -1.469831  0.008371 -0.398790   \n",
      "\n",
      "              V7        V8        V9  ...       V21       V22       V23  \\\n",
      "101598  0.792314 -0.087997 -0.424339  ... -0.251287 -0.678663  0.027646   \n",
      "251429  1.155357  0.081171 -0.408325  ... -0.141639 -0.522758 -0.182508   \n",
      "73800   0.611129 -0.102421 -0.443961  ... -0.449004 -0.717299  0.228392   \n",
      "3896    0.063992  0.386638  0.017641  ... -0.049529 -0.060215  0.177210   \n",
      "52306   0.343772  0.211678  0.064718  ... -0.113997 -0.367173 -0.110065   \n",
      "\n",
      "             V24       V25       V26       V27       V28  Amount  Class  \n",
      "101598  0.335780 -0.148321  0.070771  0.240073  0.099877   22.46      0  \n",
      "251429  0.634041  0.677099  0.060133 -0.011220  0.088029   97.01      0  \n",
      "73800  -0.000608  0.089753 -0.011570 -0.103078 -0.145532  178.90      0  \n",
      "3896   -0.122357 -1.086617  0.169358  0.052353  0.102108    9.55      0  \n",
      "52306  -0.347738 -0.232063  0.751794  0.164221  0.047261    3.69      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98186.963415</td>\n",
       "      <td>0.282766</td>\n",
       "      <td>0.019957</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>0.096275</td>\n",
       "      <td>-0.073843</td>\n",
       "      <td>-0.028649</td>\n",
       "      <td>0.044029</td>\n",
       "      <td>0.069345</td>\n",
       "      <td>-0.029788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005592</td>\n",
       "      <td>0.010877</td>\n",
       "      <td>0.064902</td>\n",
       "      <td>-0.016901</td>\n",
       "      <td>-0.067996</td>\n",
       "      <td>-0.034176</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>89.786199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80746.806911</td>\n",
       "      <td>-4.771948</td>\n",
       "      <td>3.623778</td>\n",
       "      <td>-7.033281</td>\n",
       "      <td>4.542029</td>\n",
       "      <td>-3.151225</td>\n",
       "      <td>-1.397737</td>\n",
       "      <td>-5.568731</td>\n",
       "      <td>0.570636</td>\n",
       "      <td>-2.581123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372319</td>\n",
       "      <td>0.713588</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>122.211321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time        V1        V2        V3        V4        V5  \\\n",
       "Class                                                                   \n",
       "0      98186.963415  0.282766  0.019957 -0.014089  0.096275 -0.073843   \n",
       "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
       "\n",
       "             V6        V7        V8        V9  ...       V20       V21  \\\n",
       "Class                                          ...                       \n",
       "0     -0.028649  0.044029  0.069345 -0.029788  ... -0.005592  0.010877   \n",
       "1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "Class                                                                         \n",
       "0      0.064902 -0.016901 -0.067996 -0.034176  0.008711  0.001686  0.007176   \n",
       "1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n",
       "\n",
       "           Amount  \n",
       "Class              \n",
       "0       89.786199  \n",
       "1      122.211321  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the similar datasets of legit and fraudlent\n",
    "#number of features in legit_sample-492\n",
    "legit_sample=legit.sample(n=492)\n",
    "\n",
    "#CONCATENATING TWO DATA FRAMES\n",
    "new_dataset = pd.concat([legit_sample, fraudlent], axis=0)\n",
    "print(new_dataset.head())\n",
    "\n",
    "new_dataset['Class'].value_counts()\n",
    "new_dataset.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SPLITTING THE DATA INTO FEATURES AND TARGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "101598   67889.0 -0.368669  1.095595  1.270223  0.071694 -0.019542 -0.946124   \n",
      "251429  155344.0 -0.820185  0.765186  0.568137 -0.521165  0.690793 -0.124059   \n",
      "73800    55285.0 -0.614611 -0.713327  1.756478 -2.087375 -1.096341  0.286983   \n",
      "3896      3469.0 -0.054135  0.851364  0.372174  0.627681 -0.302748 -0.380554   \n",
      "52306    45379.0 -0.358544  0.563827  1.203042 -1.469831  0.008371 -0.398790   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
      "280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
      "280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
      "281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
      "281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
      "\n",
      "              V7        V8        V9  ...       V20       V21       V22  \\\n",
      "101598  0.792314 -0.087997 -0.424339  ...  0.163220 -0.251287 -0.678663   \n",
      "251429  1.155357  0.081171 -0.408325  ...  0.252188 -0.141639 -0.522758   \n",
      "73800   0.611129 -0.102421 -0.443961  ...  0.160619 -0.449004 -0.717299   \n",
      "3896    0.063992  0.386638  0.017641  ... -0.173375 -0.049529 -0.060215   \n",
      "52306   0.343772  0.211678  0.064718  ... -0.033285 -0.113997 -0.367173   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "279863 -0.882850  0.697211 -2.064945  ...  1.252967  0.778584 -0.319189   \n",
      "280143 -1.413170  0.248525 -1.127396  ...  0.226138  0.370612  0.028234   \n",
      "280149 -2.234739  1.210158 -0.652250  ...  0.247968  0.751826  0.834108   \n",
      "281144 -2.208002  1.058733 -1.632333  ...  0.306271  0.583276 -0.269209   \n",
      "281674  0.223050 -0.068384  0.577829  ... -0.017652 -0.164350 -0.295135   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \n",
      "101598  0.027646  0.335780 -0.148321  0.070771  0.240073  0.099877   22.46  \n",
      "251429 -0.182508  0.634041  0.677099  0.060133 -0.011220  0.088029   97.01  \n",
      "73800   0.228392 -0.000608  0.089753 -0.011570 -0.103078 -0.145532  178.90  \n",
      "3896    0.177210 -0.122357 -1.086617  0.169358  0.052353  0.102108    9.55  \n",
      "52306  -0.110065 -0.347738 -0.232063  0.751794  0.164221  0.047261    3.69  \n",
      "...          ...       ...       ...       ...       ...       ...     ...  \n",
      "279863  0.639419 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00  \n",
      "280143 -0.145640 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76  \n",
      "280149  0.190944  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89  \n",
      "281144 -0.456108 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00  \n",
      "281674 -0.072173 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53  \n",
      "\n",
      "[984 rows x 30 columns]\n",
      "101598    0\n",
      "251429    0\n",
      "73800     0\n",
      "3896      0\n",
      "52306     0\n",
      "         ..\n",
      "279863    1\n",
      "280143    1\n",
      "280149    1\n",
      "281144    1\n",
      "281674    1\n",
      "Name: Class, Length: 984, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = new_dataset.drop(columns='Class', axis=1)\n",
    "Y = new_dataset['Class']\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SPLITING THE DATA INTO TRANING AND TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 30) (787, 30) (197, 30)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LOGISTIC REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model1 = LogisticRegression(max_iter=200)\n",
    "model1.fit(X_train, Y_train)\n",
    "ypred=model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.89%\n",
      "Precision: 0.97\n",
      "Recall: 0.89\n",
      "F1 Score: 0.93\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        99\n",
      "           1       0.97      0.89      0.93        98\n",
      "\n",
      "    accuracy                           0.93       197\n",
      "   macro avg       0.93      0.93      0.93       197\n",
      "weighted avg       0.93      0.93      0.93       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(\"Using Logistic Regression :\",accuracy_score(Y_test,ypred)*100)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Assuming y_test is the true labels and y_pred is the predicted labels from your model\n",
    "# Replace Y_test and ypred with your variable names if different\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(Y_test, ypred) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(Y_test, ypred)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(Y_test, ypred)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(Y_test, ypred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, ypred))\n",
    "#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.89%\n",
      "Precision: 0.97\n",
      "Recall: 0.89\n",
      "F1 Score: 0.93\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        99\n",
      "           1       0.97      0.89      0.93        98\n",
      "\n",
      "    accuracy                           0.93       197\n",
      "   macro avg       0.93      0.93      0.93       197\n",
      "weighted avg       0.93      0.93      0.93       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(\"Using Logistic Regression :\",accuracy_score(Y_test,ypred)*100)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Assuming y_test is the true labels and y_pred is the predicted labels from your model\n",
    "# Replace Y_test and ypred with your variable names if different\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(Y_test, ypred) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(Y_test, ypred)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(Y_test, ypred)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(Y_test, ypred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, ypred))\n",
    "#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 30) (227845, 30) (56962, 30)\n",
      "Before SMOTE:\n",
      "Class\n",
      "0    227451\n",
      "1       394\n",
      "Name: count, dtype: int64\n",
      "After SMOTE:\n",
      "Class\n",
      "0    227451\n",
      "1    227451\n",
      "Name: count, dtype: int64\n",
      "Accuracy Scores:\n",
      "Using Logistic Regression: 98.68157719181208\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     56864\n",
      "           1       0.11      0.93      0.20        98\n",
      "\n",
      "    accuracy                           0.99     56962\n",
      "   macro avg       0.55      0.96      0.59     56962\n",
      "weighted avg       1.00      0.99      0.99     56962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = credit_card_data.drop(columns='Class', axis=1)\n",
    "Y = credit_card_data['Class']\n",
    "\n",
    "#print(X)\n",
    "#print(Y)\n",
    "\n",
    "# SPLITTING THE DATA INTO TRAINING AND TESTING\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "print(X.shape, X_train.shape, X_test.shape)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# APPLYING OVERSAMPLING WITH SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, Y_train_resampled = smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "print(\"Before SMOTE:\")\n",
    "print(Y_train.value_counts())\n",
    "print(\"After SMOTE:\")\n",
    "print(pd.Series(Y_train_resampled).value_counts())\n",
    "\n",
    "# MODEL TRAINING\n",
    "print(\"Accuracy Scores:\")\n",
    "\n",
    "# LOGISTIC REGRESSION\n",
    "model1 = LogisticRegression(max_iter=200)\n",
    "model1.fit(X_train_resampled, Y_train_resampled)\n",
    "ypred = model1.predict(X_test)\n",
    "\n",
    "# ACCURACY AND OTHER METRICS\n",
    "print(\"Using Logistic Regression:\", accuracy_score(Y_test, ypred) * 100)\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, ypred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomUnderSAmple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Undersampling with Scaling ===\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy: 0.9646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.95      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.96      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Accuracy: 0.9626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.93      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.95      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# RANDOM UNDERSAMPLING\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, Y_rus = rus.fit_resample(X_train_scaled, Y_train)\n",
    "\n",
    "print(\"\\n=== Random Undersampling with Scaling ===\")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
    "log_reg.fit(X_rus, Y_rus)\n",
    "log_pred = log_reg.predict(X_test_scaled)\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, log_pred):.4f}\")\n",
    "print(classification_report(Y_test, log_pred))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_rus, Y_rus)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "print(\"\\nRandom Forest\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, rf_pred):.4f}\")\n",
    "print(classification_report(Y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TokenLink with Scaling ===\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy: 0.9646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.95      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.96      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Accuracy: 0.9626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.93      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.95      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# TOMEK LINKS\n",
    "tomek = TomekLinks()\n",
    "X_tomek, Y_tomek = tomek.fit_resample(X_train, Y_train)\n",
    "\n",
    "print(\"\\n=== TokenLink with Scaling ===\")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
    "log_reg.fit(X_rus, Y_rus)\n",
    "log_pred = log_reg.predict(X_test_scaled)\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, log_pred):.4f}\")\n",
    "print(classification_report(Y_test, log_pred))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_rus, Y_rus)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "print(\"\\nRandom Forest\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, rf_pred):.4f}\")\n",
    "print(classification_report(Y_test, rf_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cluster Centroids ===\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy: 0.9646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.95      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.96      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Accuracy: 0.9626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.93      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.95      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# CLUSTER CENTROIDS\n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_cc, Y_cc = cc.fit_resample(X_train, Y_train)\n",
    "\n",
    "print(\"\\n=== Cluster Centroids ===\")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
    "log_reg.fit(X_rus, Y_rus)\n",
    "log_pred = log_reg.predict(X_test_scaled)\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, log_pred):.4f}\")\n",
    "print(classification_report(Y_test, log_pred))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_rus, Y_rus)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "print(\"\\nRandom Forest\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, rf_pred):.4f}\")\n",
    "print(classification_report(Y_test, rf_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SMOTE + Tomek Links ===\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy: 0.9646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.95      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.96      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Accuracy: 0.9626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.93      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.95      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# SMOTE + TOMEK LINKS\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_smote_tomek, Y_smote_tomek = smote_tomek.fit_resample(X_train, Y_train)\n",
    "\n",
    "print(\"\\n=== SMOTE + Tomek Links ===\")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
    "log_reg.fit(X_rus, Y_rus)\n",
    "log_pred = log_reg.predict(X_test_scaled)\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, log_pred):.4f}\")\n",
    "print(classification_report(Y_test, log_pred))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_rus, Y_rus)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "print(\"\\nRandom Forest\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, rf_pred):.4f}\")\n",
    "print(classification_report(Y_test, rf_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Oversampling ===\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy: 0.9646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.95      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.96      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Accuracy: 0.9626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.93      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.95      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# RANDOM OVERSAMPLING\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, Y_ros = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "print(\"\\n=== Random Oversampling ===\")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
    "log_reg.fit(X_rus, Y_rus)\n",
    "log_pred = log_reg.predict(X_test_scaled)\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, log_pred):.4f}\")\n",
    "print(classification_report(Y_test, log_pred))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_rus, Y_rus)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "print(\"\\nRandom Forest\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, rf_pred):.4f}\")\n",
    "print(classification_report(Y_test, rf_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. SMOTE (Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SMOTE ===\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy: 0.9646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.95      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.96      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Accuracy: 0.9626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56864\n",
      "           1       0.04      0.93      0.08        98\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.95      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, Y_smote = smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "print(\"\\n=== SMOTE ===\")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
    "log_reg.fit(X_rus, Y_rus)\n",
    "log_pred = log_reg.predict(X_test_scaled)\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, log_pred):.4f}\")\n",
    "print(classification_report(Y_test, log_pred))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_rus, Y_rus)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "print(\"\\nRandom Forest\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, rf_pred):.4f}\")\n",
    "print(classification_report(Y_test, rf_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tomek Links ===\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy: 0.9991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.86      0.58      0.70        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.79      0.85     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks, RandomUnderSampler, NearMiss, EditedNearestNeighbours\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data (if not already split)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define sampling techniques\n",
    "sampling_techniques = {\n",
    "    \"Tomek Links\": TomekLinks(),\n",
    "    \"Random Under Sampling\": RandomUnderSampler(random_state=42),\n",
    "    \"Near Miss\": NearMiss(),\n",
    "    \"Edited Nearest Neighbours\": EditedNearestNeighbours(),\n",
    "    \"SMOTE (Synthetic Over Sampling)\": SMOTE(random_state=42)\n",
    "}\n",
    "\n",
    "# Loop through sampling techniques and evaluate models\n",
    "for name, sampler in sampling_techniques.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    \n",
    "    # Apply sampling\n",
    "    X_resampled, Y_resampled = sampler.fit_resample(X_train_scaled, Y_train)\n",
    "    \n",
    "    # Logistic Regression\n",
    "    log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
    "    log_reg.fit(X_resampled, Y_resampled)\n",
    "    log_pred = log_reg.predict(X_test_scaled)\n",
    "    print(\"\\nLogistic Regression\")\n",
    "    print(f\"Accuracy: {accuracy_score(Y_test, log_pred):.4f}\")\n",
    "    print(classification_report(Y_test, log_pred))\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_resampled, Y_resampled)\n",
    "    rf_pred = rf.predict(X_test_scaled)\n",
    "    print(\"\\nRandom Forest\")\n",
    "    print(f\"Accuracy: {accuracy_score(Y_test, rf_pred):.4f}\")\n",
    "    print(classification_report(Y_test, rf_pred))\n",
    "\n",
    "    # XGBoost\n",
    "    xgb = XGBClassifier(random_state=42, eval_metric=\"logloss\", n_jobs=-1)\n",
    "    xgb.fit(X_resampled, Y_resampled)\n",
    "    xgb_pred = xgb.predict(X_test_scaled)\n",
    "    print(\"\\nXGBoost\")\n",
    "    print(f\"Accuracy: {accuracy_score(Y_test, xgb_pred):.4f}\")\n",
    "    print(classification_report(Y_test, xgb_pred))\n",
    "\n",
    "    # K-Nearest Neighbors (KNN)\n",
    "    knn = KNeighborsClassifier(n_jobs=-1)\n",
    "    knn.fit(X_resampled, Y_resampled)\n",
    "    knn_pred = knn.predict(X_test_scaled)\n",
    "    print(\"\\nK-Nearest Neighbors\")\n",
    "    print(f\"Accuracy: {accuracy_score(Y_test, knn_pred):.4f}\")\n",
    "    print(classification_report(Y_test, knn_pred))\n",
    "\n",
    "    # Decision Tree\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_resampled, Y_resampled)\n",
    "    dt_pred = dt.predict(X_test_scaled)\n",
    "    print(\"\\nDecision Tree\")\n",
    "    print(f\"Accuracy: {accuracy_score(Y_test, dt_pred):.4f}\")\n",
    "    print(classification_report(Y_test, dt_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Choice:\n",
    "Model: XGBoost\n",
    "Technique: Tomek Links\n",
    "Why?:\n",
    "XGBoost is robust, performs well in imbalanced datasets, and provides a good trade-off between precision and recall.\n",
    "Tomek Links reduces noise from the dataset by removing ambiguous samples, which improves minority class performance.\n",
    "Final Metrics (XGBoost with Tomek Links):\n",
    "Accuracy: 0.9996\n",
    "Precision (Class 1): 0.96\n",
    "Recall (Class 1): 0.79\n",
    "F1-score (Class 1): 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.934010152284264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94        99\n",
      "           1       0.98      0.89      0.93        98\n",
      "\n",
      "    accuracy                           0.93       197\n",
      "   macro avg       0.94      0.93      0.93       197\n",
      "weighted avg       0.94      0.93      0.93       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply Tomek Links\n",
    "tomek = TomekLinks()\n",
    "X_resampled, Y_resampled = tomek.fit_resample(X_train_scaled, Y_train)\n",
    "\n",
    "# Train XGBoost\n",
    "model = XGBClassifier(random_state=42, eval_metric=\"logloss\")\n",
    "model.fit(X_resampled, Y_resampled)\n",
    "\n",
    "# Evaluate\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'xgb_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "# Save and load the model\n",
    "joblib.dump(model, \"xgb_model.pkl\")\n",
    "print(\"Model saved as 'xgb_model.pkl'.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
